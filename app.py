import streamlit as st
from streamlit_drawable_canvas import st_canvas
import tensorflow as tf
from tensorflow.keras import layers, models
import numpy as np
import cv2
import os
import streamlit.components.v1 as components
import re

# è¨­å®šç¶²é è³‡è¨Š
st.set_page_config(page_title="AI æ•¸å­—å…¨èƒ½è¾¨è­˜", layout="centered")
st.title("ğŸ”¢ AI æ•¸å­—å…¨èƒ½è¾¨è­˜ç³»çµ±")
st.markdown("### æ”¯æ´ã€Œæ‰‹å¯«ã€èˆ‡ã€ŒèªéŸ³ã€é›™æ¨¡è¾¨è­˜")

# --- 1. æ¨¡å‹èˆ‡é è™•ç†é‚è¼¯ (ä¿æŒä¸è®Š) ---
MODEL_PATH = 'mnist_model_v2.h5'
@st.cache_resource
def get_model():
    if not os.path.exists(MODEL_PATH):
        mnist = tf.keras.datasets.mnist
        (x_train, y_train), _ = mnist.load_data()
        x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0
        model = models.Sequential([
            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
            layers.MaxPooling2D((2, 2)),
            layers.Conv2D(64, (3, 3), activation='relu'),
            layers.MaxPooling2D((2, 2)),
            layers.Flatten(),
            layers.Dense(128, activation='relu'),
            layers.Dense(10, activation='softmax')
        ])
        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
        model.fit(x_train, y_train, epochs=5, verbose=0)
        model.save(MODEL_PATH)
    return tf.keras.models.load_model(MODEL_PATH)

model = get_model()

def pre_process_digit(roi):
    if roi.size == 0: return None, None
    h, w = roi.shape
    new_h, new_w = (20, int(20*w/h)) if h > w else (int(20*h/w), 20)
    roi_resized = cv2.resize(roi, (max(1, new_w), max(1, new_h)))
    final_img = np.zeros((28, 28), dtype=np.uint8)
    final_img[(28-new_h)//2:(28-new_h)//2+new_h, (28-new_w)//2:(28-new_w)//2+new_w] = roi_resized
    return final_img.reshape(1, 28, 28, 1).astype('float32') / 255.0, final_img

# --- æ–°å¢ï¼šä¸­è‹±æ–‡æ•¸å­—è½‰æ›é‚è¼¯ ---
def text_to_digit(text):
    if not text: return ""
    # å»ºç«‹è½‰æ›å­—å…¸
    mapping = {
        'é›¶': '0', 'ä¸€': '1', 'äºŒ': '2', 'å…©': '2', 'ä¸‰': '3', 'å››': '4', 'äº”': '5', 'å…­': '6', 'ä¸ƒ': '7', 'å…«': '8', 'ä¹': '9',
        'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4', 'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9'
    }
    text = text.lower()
    # è™•ç†åŸæœ¬å°±æ˜¯é˜¿æ‹‰ä¼¯æ•¸å­—çš„æƒ…æ³
    digits = re.findall(r'\d', text)
    if digits: return "".join(digits)
    
    # è™•ç†é€å­—/é€è©è½‰æ›
    res = ""
    for char in text:
        if char in mapping: res += mapping[char]
    if not res:
        for word in text.split():
            if word in mapping: res += mapping[word]
    return res

# --- 2. èªéŸ³è¾¨è­˜åŠŸèƒ½ (Web Speech API) ---
st.subheader("ğŸ¤ èªéŸ³è¾¨è­˜æ•¸å­—")
st.info("é»æ“Šä¸‹æ–¹æŒ‰éˆ•å¾Œï¼Œè«‹å°è‘—éº¥å…‹é¢¨èªªå‡ºæ•¸å­—ï¼ˆä¾‹å¦‚ï¼šä¸€äºŒä¸‰ æˆ– One Two Threeï¼‰")

# æ¥æ”¶èªéŸ³åƒæ•¸ä¸¦è½‰æ›
voice_raw = st.query_params.get("voice_input", "")
voice_final = text_to_digit(voice_raw)

# JavaScript è…³æœ¬ (ä¿®æ­£å‚³å€¼é‚è¼¯ä»¥ç¢ºä¿å³æ™‚é¡¯ç¤º)
speech_script = """
<script>
const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
recognition.lang = 'zh-TW'; 
recognition.interimResults = false;

function startListen() {
    recognition.start();
    recognition.onresult = (event) => {
        const text = event.results[0][0].transcript;
        // ä½¿ç”¨ window.top.location ç¢ºä¿ç¹é iframe
